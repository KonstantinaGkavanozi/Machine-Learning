{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ7YzabwjTmk"
      },
      "source": [
        "## Εργασία 3 ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egArYhcsTG-T"
      },
      "source": [
        "**1** Διαβάστε το διαθέσιμο από την sklearn σύνολο δεδομένων breast cancer, χωρίστε το σε δεδομένα εκπαίδευσης (X_train, y_train) και ελέγχου (X_test, y_test) σε ποσοστό 70%/30% αντίστοιχα με τη συνάρτηση train_test_split (τιμή για random_state βάλτε 0). Το σύνολο αφορά τη διάγνωση καρκίνου του μαστού με βάση μεταβλητές που υπολογίζονται από μια ψηφιοποιημένη εικόνα δείγματος μάζας μαστού που λήφθηκε μέσω αναρρόφησης λεπτής βελόνας (FNA). (2 μονάδες)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "qgaPtNAmTCX7",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "29b99b6039fac516d5fa9c7649e40e1d",
          "grade": false,
          "grade_id": "cell-407a2dea48bfbf80",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Import from sklearn dataset for breast cancer\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "random_state = 0\n",
        "# Split the data into training and test sets with 70% training and 30% test data\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "19LlgZx5cOLP",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e4b7add4e469cfc1221bdad01497d404",
          "grade": true,
          "grade_id": "cell-7387a72f2393ed9a",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"Τεστ ορθής ανάγνωσης και διαχωρισμού του συνόλου δεδομένων\"\"\"\n",
        "assert round(X_train[0][8], 5) == 0.1779\n",
        "assert round(X_test[0][8], 5) == 0.2116"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB8RexuPciQr"
      },
      "source": [
        "**2** Υλοποιήστε μια ντετερμινιστική εκδοχή της μεθόδου των τυχαίων υποχώρων, η οποία χτίζει τόσα μοντέλα όσες και οι μεταβλητές εισόδου, κάθε ένα από τα οποία αγνοεί και μία διαφορετική μεταβλητή εισόδου. Π.χ. το πρώτο μοντέλο αγνοεί την πρώτη, το δεύτερο αγνοεί τη δεύτερη κτλ. Χρησιμοποιήστε τη συνάρτηση clone από το sklearn.base για να δημιουργήστε αντίγραφο του βασικού μοντέλου σε κάθε επανάληψη. (4 μονάδες)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "id": "KuC_s04KcigR",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5fbe3d9c3d8e46ffc9d9cf06a7644fa3",
          "grade": false,
          "grade_id": "cell-df57dc0d540a2518",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import clone\n",
        "\n",
        "class RandomSubspaceDet:\n",
        "    def __init__(self, estimator=DecisionTreeClassifier()):\n",
        "\n",
        "        #Initializing the class parameters\n",
        "        self.estimator = estimator\n",
        "        self.models = []\n",
        "        self.used_features = []\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "\n",
        "        n_features = X_train.shape[1]\n",
        "\n",
        "        for i in range(n_features):\n",
        "            #Creating a new dataset deleting the i-th element\n",
        "            X_new = np.delete(X_train, i, axis=1)\n",
        "\n",
        "            #Cloning the initial estimator\n",
        "            model = clone(self.estimator)\n",
        "\n",
        "            #Training the model in the new training set\n",
        "            model.fit(X_new, y_train)\n",
        "\n",
        "            #Storing the new model and features\n",
        "            self.models.append(model)\n",
        "            self.used_features.append(np.delete(np.arange(n_features), i))\n",
        "\n",
        "    def predict(self, X):\n",
        "\n",
        "        predictions = np.zeros((X.shape[0], len(self.models)))\n",
        "\n",
        "        for i, model in enumerate(self.models):\n",
        "            #Creating a new set deleting the i-th element\n",
        "            X_new = np.delete(X, i, axis=1)\n",
        "\n",
        "            #Making the predictions\n",
        "            predictions[:, i] = model.predict(X_new)\n",
        "\n",
        "        #Getting the final prediction\n",
        "        final_predictions = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=predictions)\n",
        "\n",
        "        return final_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "iDNUeGUEciwi",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4db933425279be3712175509b4ba2f53",
          "grade": true,
          "grade_id": "cell-786f87fa5e67b624",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"Τεστ ορθής υλοποίησης RandomSubspaceDet\"\"\"\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rs = RandomSubspaceDet(estimator=DecisionTreeClassifier(random_state=1))\n",
        "rs.fit(X_train, y_train)\n",
        "assert round(accuracy_score(rs.predict(X_test), y_test), 4) == 0.9006"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n19eEYRNRnG-"
      },
      "source": [
        "**3** Υλοποιήστε τη μέθοδο AdaBoost όπως παρουσιάστηκε στο μάθημα. Χρησιμοποιήστε τη συνάρτηση clone από το sklearn.base για να δημιουργήστε αντίγραφο του βασικού μοντέλου σε κάθε επανάληψη. Χρησιμοποιήστε την παράμετρο sample_weight της fit του βασικού μοντέλου για να ορίσετε τα βάρη των παραδειγμάτων εκπαίδευσης. (4 μονάδες)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow0o__fqcVd5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.base import clone\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class AdaBoost:\n",
        "    def __init__(self, n_estimators=20, estimator=DecisionTreeClassifier(max_depth=1)):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.estimator = estimator\n",
        "\n",
        "        self.estimators = None\n",
        "        self.estimator_weights = None\n",
        "\n",
        "        self.total_errors = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "\n",
        "        self.estimators = []\n",
        "        self.estimator_weights = []\n",
        "        self.total_errors = []\n",
        "\n",
        "        weights = np.full(len(X_train), 1/len(X_train))\n",
        "\n",
        "        for est_i in range(self.n_estimators):\n",
        "            #Cloning the basic estimator and training it using the current train set\n",
        "            estimator = clone(self.estimator)\n",
        "            estimator.fit(X_train, y_train, weights)\n",
        "\n",
        "            #Making predictions and calculating the error\n",
        "            prediction = estimator.predict(X_train)\n",
        "            error = np.where(prediction != y_train, weights, 0).sum()\n",
        "\n",
        "            #Calculating the alpha using the error\n",
        "            alpha = 0.5 *np.log((1 - error)/error)\n",
        "\n",
        "            #Saving the estimator and the alpha\n",
        "            self.estimators.append(estimator)\n",
        "            self.estimator_weights.append(alpha)\n",
        "\n",
        "            #Updating the weights\n",
        "            weights = np.where(prediction != y_train, weights * np.exp(alpha), weights * np.exp(-1 * alpha))\n",
        "\n",
        "            #Normalizing the weights so that they sum up to 1\n",
        "            weights = weights / weights.sum()\n",
        "\n",
        "            #Saving the error\n",
        "            self.total_errors.append(error)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = np.stack([estimator.predict(X) for estimator in self.estimators], axis=1)\n",
        "        weighted_majority_vote = lambda x: np.unique(x)[np.argmax([np.where(x==categ, self.estimator_weights, 0).sum() for categ in np.unique(x)])]\n",
        "        return np.apply_along_axis(weighted_majority_vote, axis=1, arr=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "jVjqVcv_tmYk",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "32aff6a2c5ed06a7b34e982fc295d895",
          "grade": true,
          "grade_id": "cell-88a2903df26757f7",
          "locked": true,
          "points": 4,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"Τεστ ορθής υλοποίησης AdaBoost\"\"\"\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ab = AdaBoost(n_estimators=20, estimator=DecisionTreeClassifier(max_depth=1, random_state=1))\n",
        "ab.fit(X_train, y_train)\n",
        "assert round(accuracy_score(ab.predict(X_test), y_test), 4) == 0.9591\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "0QkPMoBNz3T5",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "71c5a522427b4fc254b65b5d431a767d",
          "grade": false,
          "grade_id": "cell-4f6f954c3531f480",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Ίδιο αποτέλεσμα και με τη κλάση της sklearn\n",
        "ab = AdaBoostClassifier(n_estimators=20, algorithm=\"SAMME\", estimator=DecisionTreeClassifier(max_depth=1, random_state=1))\n",
        "ab.fit(X_train, y_train)\n",
        "assert round(accuracy_score(ab.predict(X_test), y_test), 4) == 0.9591"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
